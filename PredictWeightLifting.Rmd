---
title: "Practical Machine Learning Project - Predict Weightlifting Fashion"
author: "Michael Lioznov"
output:
  html_document:
    keep_md: yes
  pdf_document: default
  word_document: default
---
# **Synopsis**

Goal of this project is to devise prediction model for predicting the way in which weightlifting exercise participants perform barbell lifts based on data from accelerometers on their belt, forearm, arm, and dumbbell. Participants can perform barbell lifts correctly and incorrectly in 5 different ways: 

 Class A - correctly per specification.
 
 Class B - throwing the elbows to the front.
 
 Class C - lifting the dumbbell only halfway.
 
 Class B - lowering the dumbbell only halfway.
 
 Class E - throwing the hips to the front.

More information is available here: http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises


# **Data Load and Preparation**

Load required packages
```{r, echo=TRUE}
# load the required packages
suppressMessages(library(caret)); 
suppressMessages(library(rattle)); 
suppressMessages(library(rpart)); 
suppressMessages(library(rpart.plot))
suppressMessages(library(randomForest));
```

Load training and testing data
```{r, echo=TRUE}
# load training and testing data
setwd("C:/Users/egdbb48/PracticalMachineLearning/CourseProject")
download.file(url="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",destfile="TrainingData.csv")
download.file(url="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",destfile="TestingData.csv")
testing <- read.csv("TestingData.csv", na.strings = c("NA", "" ,"#DIV/0!"), header = TRUE)
training <- read.csv("TrainingData.csv", na.strings = c("NA", "", "#DIV/0!"), header = TRUE)
```  

Exploration of the training and testing sets shows a lot of undefined variables that cannot and should not be used as predictors; also the first 7 variables (X, user_name, raw_timestamp_part_1, raw_timestamp_part_2,   cvtd_timestamp, new_window, num_window) obviously cannot correllate with the weightlifting mannors demonstrated by participants.

Cleansing datasets from nonsensical fields:
```{r, echo=TRUE}
# Clean test set first - to limit useful predictors:
testClean <- testing[,colSums(is.na(testing)) == 0 ][, -c(1:7)] # & !(colnames(testing) %in% c("problem_id"))
# Find which predictors in the training set should be chosen for modeling mannor of weightlifting (classe)
ColNames <- names(testClean[, !(colnames(testClean) %in% c("problem_id"))])
# Subset the training set
trainClean <- training[ ,c(ColNames,"classe")] # tail(trainClean) 
#names(trainClean)
```  


# **Data partitioning**
To tune and compare possible models before using them on the testing (testClean) data set the training set was split into the training (Train) and validation (Validate) data sets
```{r, echo=TRUE}
set.seed(4321)
PartitionFunc <- createDataPartition(y=trainClean$classe, p=3/4, list=FALSE)
Train <- trainClean[PartitionFunc, ]
Validate <- trainClean[-PartitionFunc, ]
```  

# **Compare Prediction Algorithms**

Random Forests (rf) and Classification Trees (rpart) were compared for accuracy.

## **Classification Trees**
For Classification Trees the 20 - fold cross validation was used:
```{r, echo=TRUE} 
contr <- trainControl(method = "cv", number = 20)
Modelrpart <- train(classe ~ ., data = Train, method = "rpart",trControl = contr) 
print(Modelrpart, digits = 4)
``` 


```{r, echo=TRUE}
fancyRpartPlot(Modelrpart$finalModel)
```

```{r, echo=TRUE}
# Run prediction and show results on Validation set
PredictOnValidateRPART <- predict(Modelrpart, Validate)
confusionMatrix(Validate$classe, PredictOnValidateRPART)
```
The prediction attempt on the Validation set shows unsatisfactory accuracy of `r confusionMatrix(Validate$classe, PredictOnValidateRPART)$overall["Accuracy"]` and out-of-sample error rate of `r 1 - confusionMatrix(Validate$classe, PredictOnValidateRPART)$overall["Accuracy"]`

## **Random Forests**


```{r, echo=TRUE}
Modelrf <- train(classe ~ .,data=Train,method='rf',ntree=100)
print(Modelrf, digits = 4) 
```

The following prediction attempt on the Validation set shows great accuracy:

```{r, echo=TRUE}
# Run prediction and show results on Validation set
PredictOnValidateRf <- predict(Modelrf, Validate)
confusionMatrix(Validate$classe, PredictOnValidateRf)
```

# **Conclusion**
Prediction accuracy of `r confusionMatrix(Validate$classe, PredictOnValidateRf)$overall["Accuracy"]` is achieved by using RandomForests algorithm. The out-of-sample error rate for the Random Forests algorithm is `r 1 - confusionMatrix(Validate$classe, PredictOnValidateRf)$overall["Accuracy"]`. Although many predictors seem highly correlated, Random Forests algorithm chooses a subset of predictors at each split. This leads to high accuracy.

Random Forests algorythm was used for predicting weightlifting fashions in the testing set
```{r, echo=TRUE}
# TestPrediction <- predict(Modelrf, newdata=testClean)
# TestPredictionResults <- data.frame(problem_id=testClean$problem_id,predicted=TestPrediction)
# print(TestPredictionResults)
```


